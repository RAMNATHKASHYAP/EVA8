# Import necessary modules from PyTorch library
from __future__ import print_function
import torch
import torch.nn as nn # module for building neural networks
import torch.nn.functional as F # functional interface for building neural networks
import torch.optim as optim # module for optimization algorithms
from torchvision import datasets, transforms # modules for loading and preprocessing data


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # Define 2D convolutional layer with 1 input channel, 16 output channels and kernel size of 3
        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)
        # Define batch normalization layer for output of conv1
        self.bn1 = nn.BatchNorm2d(16)
        # Define 2D convolutional layer with 16 input channels, 32 output channels and kernel size of 3
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        # Define batch normalization layer for output of conv2
        self.bn2 = nn.BatchNorm2d(32)
        # Define max pooling layer with kernel size of 2 and stride of 2
        self.pool = nn.MaxPool2d(2, 2)
        # Define 2D convolutional layer with 32 input channels, 64 output channels and kernel size of 3
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)
        # Define batch normalization layer for output of conv3
        self.bn3 = nn.BatchNorm2d(64)
        # Define 2D convolutional layer with 64 input channels, 128 output channels and kernel size of 3
        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)
        # Define batch normalization layer for output of conv4
        self.bn4 = nn.BatchNorm2d(128)
        # Define 2D convolutional layer with 128 input channels and 256 output channels, and kernel size of 3
        self.conv5 = nn.Conv2d(128, 256, 3)
        # Define batch normalization layer for output of conv5
        self.bn5 = nn.BatchNorm2d(256)
        # Define AdaptiveAvgPool2d layer to aggregate global spatial information and reduce the spatial dimensions
        self.gap = nn.AdaptiveAvgPool2d(1)
        # Define fully connected linear layer with 256 input channels and 10 output channels
        self.fc = nn.Linear(256, 10)
        # Define dropout layer with drop probability of 0.25
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        # Apply conv1, bn1, relu, pool, conv2, bn2, relu, pool, conv3, bn3, relu, conv4, bn4, relu, conv5, bn5, relu, adaptive avg pool and dropout layers in sequence to input tensor x
        x = self.pool(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))
        x = self.pool(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))
        x = self.gap(F.relu(self.bn5(self.conv5(x))))
        # Reshape tensor to have shape of (-1, 256)
        x = x.view(-1, 256)
        # Apply dropout
        x = self.dropout(x)
        # Apply fully connected linear layer
        x = self.fc(x)
        # Apply log_softmax function to output along second dimension (dim=1)
        return F.log_softmax(x, dim=1)


# Install torchsummary package
!pip install torchsummary

# Import summary function from torchsummary
from torchsummary import summary

# Check if CUDA-enabled GPU is available
use_cuda = torch.cuda.is_available()

# Set device to "cuda" if GPU is available, otherwise set to "cpu"
device = torch.device("cuda" if use_cuda else "cpu")

# Create an instance of the Net class and move to specified device
model = Net().to(device)

# Display a summary of the model's architecture, including number of trainable parameters and output size of each layer
summary(model, input_size=(1, 28, 28))


      Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 28, 28]             160
       BatchNorm2d-2           [-1, 16, 28, 28]              32
            Conv2d-3           [-1, 32, 28, 28]           4,640
       BatchNorm2d-4           [-1, 32, 28, 28]              64
         MaxPool2d-5           [-1, 32, 14, 14]               0
            Conv2d-6           [-1, 64, 14, 14]          18,496
       BatchNorm2d-7           [-1, 64, 14, 14]             128
            Conv2d-8          [-1, 128, 14, 14]          73,856
       BatchNorm2d-9          [-1, 128, 14, 14]             256
        MaxPool2d-10            [-1, 128, 7, 7]               0
           Conv2d-11            [-1, 256, 5, 5]         295,168
      BatchNorm2d-12            [-1, 256, 5, 5]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
          Dropout-14                  [-1, 256]               0
           Linear-15                   [-1, 10]           2,570
================================================================
Total params: 395,882
Trainable params: 395,882
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.35
Params size (MB): 1.51
Estimated Total Size (MB): 2.86



# Set random seed for reproducibility
torch.manual_seed(1)

# Set batch size for dataloaders
batch_size = 128

# Create kwargs dictionary for DataLoader
if use_cuda:
    kwargs = {'num_workers': 1, 'pin_memory': True}
else:
    kwargs = {}

# Create train_loader using DataLoader class
# MNIST training dataset is downloaded if not present and transformed using ToTensor() and Normalize()
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                    transform=transforms.Compose([
                        transforms.ToTensor(),
                        transforms.Normalize((0.1307,), (0.3081,))
                    ])),
    batch_size=batch_size, shuffle=True, **kwargs)

# Create test_loader using DataLoader class
# MNIST testing dataset is transformed using ToTensor() and Normalize()
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                        transforms.ToTensor(),
                        transforms.Normalize((0.1307,), (0.3081,))
                    ])),
    batch_size=batch_size, shuffle=True, **kwargs)
    
            Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz
  0%|          | 0/9912422 [00:00<?, ?it/s]
Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz
  0%|          | 0/28881 [00:00<?, ?it/s]
Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz
  0%|          | 0/1648877 [00:00<?, ?it/s]
Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz
  0%|          | 0/4542 [00:00<?, ?it/s]
Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw
